Epoch 1/40
2017-07-11 04:21:33.767693: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-11 04:21:33.767741: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-11 04:21:33.767750: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-11 04:21:33.767756: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-11 04:21:33.767764: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-07-11 04:21:33.925989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-07-11 04:21:33.926525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1e.0
Total memory: 11.17GiB
Free memory: 11.11GiB
2017-07-11 04:21:33.926571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0
2017-07-11 04:21:33.926579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y
2017-07-11 04:21:33.926593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)



   1/1000 [..............................] - ETA: 16273s - loss: 1.4299 - amazon_score: 0.4306 - acc: 0.35662017-07-11 04:21:50.616747: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2522 get requests, put_count=2167 evicted_count=1000 eviction_rate=0.461467 and unsatisfied allocation rate=0.576923
2017-07-11 04:21:50.616798: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
  17/1000 [..............................] - ETA: 2188s - loss: 0.4284 - amazon_score: 0.6721 - acc: 0.84602017-07-11 04:22:12.073531: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2544 get requests, put_count=2450 evicted_count=1000 eviction_rate=0.408163 and unsatisfied allocation rate=0.439072
2017-07-11 04:22:12.073578: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 256 to 281
  52/1000 [>.............................] - ETA: 1554s - loss: 0.3135 - amazon_score: 0.7134 - acc: 0.89182017-07-11 04:22:59.016627: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 10335 get requests, put_count=10312 evicted_count=1000 eviction_rate=0.0969744 and unsatisfied allocation rate=0.104693
2017-07-11 04:22:59.016676: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 655 to 720
 999/1000 [============================>.] - ETA: 1s - loss: 0.2320 - amazon_score: 0.7607 - acc: 0.9150Epoch 00000: val_loss improved from inf to 0.19825, saving model to weights-v9.hdf5
1000/1000 [==============================] - 1495s - loss: 0.2320 - amazon_score: 0.7607 - acc: 0.9150 - val_loss: 0.1983 - val_amazon_score: 0.7674 - val_acc: 0.9225
Epoch 2/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.1739 - amazon_score: 0.8166 - acc: 0.9314Epoch 00001: val_loss improved from 0.19825 to 0.16209, saving model to weights-v9.hdf5
1000/1000 [==============================] - 1475s - loss: 0.1739 - amazon_score: 0.8166 - acc: 0.9314 - val_loss: 0.1621 - val_amazon_score: 0.8263 - val_acc: 0.9366
Epoch 3/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.1552 - amazon_score: 0.8395 - acc: 0.9383Epoch 00002: val_loss did not improve
1000/1000 [==============================] - 1475s - loss: 0.1552 - amazon_score: 0.8395 - acc: 0.9383 - val_loss: 0.1673 - val_amazon_score: 0.8432 - val_acc: 0.9400
Epoch 4/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.1465 - amazon_score: 0.8494 - acc: 0.9418Epoch 00003: val_loss improved from 0.16209 to 0.13749, saving model to weights-v9.hdf5
1000/1000 [==============================] - 1478s - loss: 0.1465 - amazon_score: 0.8494 - acc: 0.9417 - val_loss: 0.1375 - val_amazon_score: 0.8649 - val_acc: 0.9442
Epoch 5/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.1385 - amazon_score: 0.8572 - acc: 0.9449Epoch 00004: val_loss did not improve
1000/1000 [==============================] - 1476s - loss: 0.1385 - amazon_score: 0.8572 - acc: 0.9449 - val_loss: 0.1787 - val_amazon_score: 0.8391 - val_acc: 0.9364
Epoch 6/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.1329 - amazon_score: 0.8639 - acc: 0.9473Epoch 00005: val_loss improved from 0.13749 to 0.12829, saving model to weights-v9.hdf5
1000/1000 [==============================] - 1479s - loss: 0.1329 - amazon_score: 0.8639 - acc: 0.9473 - val_loss: 0.1283 - val_amazon_score: 0.8667 - val_acc: 0.9498
Epoch 7/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.1259 - amazon_score: 0.8710 - acc: 0.9504Epoch 00006: val_loss did not improve
1000/1000 [==============================] - 1464s - loss: 0.1259 - amazon_score: 0.8710 - acc: 0.9504 - val_loss: 0.1288 - val_amazon_score: 0.8656 - val_acc: 0.9499
Epoch 8/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.1222 - amazon_score: 0.8762 - acc: 0.9519Epoch 00007: val_loss improved from 0.12829 to 0.11914, saving model to weights-v9.hdf5
1000/1000 [==============================] - 1469s - loss: 0.1222 - amazon_score: 0.8762 - acc: 0.9520 - val_loss: 0.1191 - val_amazon_score: 0.8797 - val_acc: 0.9535
Epoch 9/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.1185 - amazon_score: 0.8801 - acc: 0.9534Epoch 00008: val_loss did not improve
1000/1000 [==============================] - 1466s - loss: 0.1186 - amazon_score: 0.8801 - acc: 0.9534 - val_loss: 0.1334 - val_amazon_score: 0.8715 - val_acc: 0.9495
Epoch 10/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.1153 - amazon_score: 0.8834 - acc: 0.9546Epoch 00009: val_loss did not improve
1000/1000 [==============================] - 1466s - loss: 0.1153 - amazon_score: 0.8834 - acc: 0.9546 - val_loss: 0.1280 - val_amazon_score: 0.8702 - val_acc: 0.9510
Epoch 11/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.1133 - amazon_score: 0.8862 - acc: 0.9556Epoch 00010: val_loss did not improve

Epoch 00010: reducing learning rate to 0.00020000000949949026.
1000/1000 [==============================] - 1467s - loss: 0.1133 - amazon_score: 0.8861 - acc: 0.9556 - val_loss: 0.1292 - val_amazon_score: 0.8711 - val_acc: 0.9494
Epoch 12/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.1034 - amazon_score: 0.8967 - acc: 0.9596Epoch 00011: val_loss improved from 0.11914 to 0.10089, saving model to weights-v9.hdf5
1000/1000 [==============================] - 1464s - loss: 0.1034 - amazon_score: 0.8967 - acc: 0.9596 - val_loss: 0.1009 - val_amazon_score: 0.8988 - val_acc: 0.9603
Epoch 13/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0986 - amazon_score: 0.9001 - acc: 0.9614Epoch 00012: val_loss did not improve
1000/1000 [==============================] - 1462s - loss: 0.0986 - amazon_score: 0.9002 - acc: 0.9614 - val_loss: 0.1014 - val_amazon_score: 0.8987 - val_acc: 0.9608
Epoch 14/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0991 - amazon_score: 0.9008 - acc: 0.9613Epoch 00013: val_loss improved from 0.10089 to 0.09836, saving model to weights-v9.hdf5
1000/1000 [==============================] - 1464s - loss: 0.0991 - amazon_score: 0.9008 - acc: 0.9613 - val_loss: 0.0984 - val_amazon_score: 0.9012 - val_acc: 0.9620
Epoch 15/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0967 - amazon_score: 0.9030 - acc: 0.9622Epoch 00014: val_loss did not improve
1000/1000 [==============================] - 1462s - loss: 0.0967 - amazon_score: 0.9030 - acc: 0.9622 - val_loss: 0.1009 - val_amazon_score: 0.8972 - val_acc: 0.9616
Epoch 16/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0969 - amazon_score: 0.9028 - acc: 0.9620Epoch 00015: val_loss did not improve
1000/1000 [==============================] - 1461s - loss: 0.0968 - amazon_score: 0.9028 - acc: 0.9620 - val_loss: 0.1008 - val_amazon_score: 0.9003 - val_acc: 0.9613
Epoch 17/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0967 - amazon_score: 0.9040 - acc: 0.9622Epoch 00016: val_loss did not improve

Epoch 00016: reducing learning rate to 4.0000001899898055e-05.
1000/1000 [==============================] - 1462s - loss: 0.0967 - amazon_score: 0.9041 - acc: 0.9622 - val_loss: 0.0992 - val_amazon_score: 0.9007 - val_acc: 0.9618
Epoch 18/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0920 - amazon_score: 0.9083 - acc: 0.9638Epoch 00017: val_loss improved from 0.09836 to 0.09520, saving model to weights-v9.hdf5
1000/1000 [==============================] - 1464s - loss: 0.0920 - amazon_score: 0.9084 - acc: 0.9639 - val_loss: 0.0952 - val_amazon_score: 0.9044 - val_acc: 0.9631
Epoch 19/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0923 - amazon_score: 0.9077 - acc: 0.9640Epoch 00018: val_loss did not improve
1000/1000 [==============================] - 1462s - loss: 0.0923 - amazon_score: 0.9077 - acc: 0.9640 - val_loss: 0.0966 - val_amazon_score: 0.9038 - val_acc: 0.9618
Epoch 20/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0926 - amazon_score: 0.9072 - acc: 0.9639Epoch 00019: val_loss did not improve
1000/1000 [==============================] - 1462s - loss: 0.0927 - amazon_score: 0.9072 - acc: 0.9639 - val_loss: 0.0964 - val_amazon_score: 0.9010 - val_acc: 0.9630
Epoch 21/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0930 - amazon_score: 0.9070 - acc: 0.9639Epoch 00020: val_loss improved from 0.09520 to 0.09433, saving model to weights-v9.hdf5
1000/1000 [==============================] - 1465s - loss: 0.0930 - amazon_score: 0.9070 - acc: 0.9639 - val_loss: 0.0943 - val_amazon_score: 0.9059 - val_acc: 0.9635
Epoch 22/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0910 - amazon_score: 0.9092 - acc: 0.9644Epoch 00021: val_loss did not improve
1000/1000 [==============================] - 1458s - loss: 0.0910 - amazon_score: 0.9092 - acc: 0.9644 - val_loss: 0.0962 - val_amazon_score: 0.9049 - val_acc: 0.9632
Epoch 23/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0906 - amazon_score: 0.9098 - acc: 0.9648Epoch 00022: val_loss did not improve
1000/1000 [==============================] - 1458s - loss: 0.0906 - amazon_score: 0.9098 - acc: 0.9648 - val_loss: 0.0947 - val_amazon_score: 0.9053 - val_acc: 0.9636
Epoch 24/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0902 - amazon_score: 0.9095 - acc: 0.9646Epoch 00023: val_loss did not improve

Epoch 00023: reducing learning rate to 8.000000525498762e-06.
1000/1000 [==============================] - 1458s - loss: 0.0903 - amazon_score: 0.9095 - acc: 0.9645 - val_loss: 0.0954 - val_amazon_score: 0.9041 - val_acc: 0.9625
Epoch 25/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0913 - amazon_score: 0.9089 - acc: 0.9642Epoch 00024: val_loss improved from 0.09433 to 0.09351, saving model to weights-v9.hdf5
1000/1000 [==============================] - 1460s - loss: 0.0913 - amazon_score: 0.9089 - acc: 0.9642 - val_loss: 0.0935 - val_amazon_score: 0.9077 - val_acc: 0.9636
Epoch 26/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0899 - amazon_score: 0.9106 - acc: 0.9649Epoch 00025: val_loss did not improve
1000/1000 [==============================] - 1458s - loss: 0.0899 - amazon_score: 0.9106 - acc: 0.9649 - val_loss: 0.0945 - val_amazon_score: 0.9058 - val_acc: 0.9630
Epoch 27/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0890 - amazon_score: 0.9105 - acc: 0.9652Epoch 00026: val_loss did not improve
1000/1000 [==============================] - 1458s - loss: 0.0890 - amazon_score: 0.9105 - acc: 0.9652 - val_loss: 0.0952 - val_amazon_score: 0.9060 - val_acc: 0.9627
Epoch 28/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0908 - amazon_score: 0.9091 - acc: 0.9645Epoch 00027: val_loss did not improve

Epoch 00027: reducing learning rate to 1.6000001778593287e-06.
1000/1000 [==============================] - 1462s - loss: 0.0908 - amazon_score: 0.9091 - acc: 0.9645 - val_loss: 0.0958 - val_amazon_score: 0.9029 - val_acc: 0.9627
Epoch 29/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0902 - amazon_score: 0.9097 - acc: 0.9646Epoch 00028: val_loss did not improve
1000/1000 [==============================] - 1463s - loss: 0.0903 - amazon_score: 0.9097 - acc: 0.9646 - val_loss: 0.0957 - val_amazon_score: 0.9047 - val_acc: 0.9630
Epoch 30/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0882 - amazon_score: 0.9113 - acc: 0.9658Epoch 00029: val_loss did not improve

Epoch 00029: reducing learning rate to 3.200000264769187e-07.
1000/1000 [==============================] - 1463s - loss: 0.0883 - amazon_score: 0.9113 - acc: 0.9658 - val_loss: 0.0942 - val_amazon_score: 0.9060 - val_acc: 0.9629
Epoch 31/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0909 - amazon_score: 0.9085 - acc: 0.9648Epoch 00030: val_loss did not improve
1000/1000 [==============================] - 1463s - loss: 0.0909 - amazon_score: 0.9085 - acc: 0.9648 - val_loss: 0.0945 - val_amazon_score: 0.9061 - val_acc: 0.9629
Epoch 32/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0898 - amazon_score: 0.9111 - acc: 0.9649Epoch 00031: val_loss improved from 0.09351 to 0.09036, saving model to weights-v9.hdf5
1000/1000 [==============================] - 1465s - loss: 0.0897 - amazon_score: 0.9111 - acc: 0.9649 - val_loss: 0.0904 - val_amazon_score: 0.9100 - val_acc: 0.9645
Epoch 33/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0897 - amazon_score: 0.9096 - acc: 0.9650Epoch 00032: val_loss did not improve
1000/1000 [==============================] - 1463s - loss: 0.0897 - amazon_score: 0.9096 - acc: 0.9650 - val_loss: 0.0937 - val_amazon_score: 0.9057 - val_acc: 0.9634
Epoch 34/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0888 - amazon_score: 0.9114 - acc: 0.9653Epoch 00033: val_loss did not improve
1000/1000 [==============================] - 1463s - loss: 0.0888 - amazon_score: 0.9114 - acc: 0.9653 - val_loss: 0.0944 - val_amazon_score: 0.9058 - val_acc: 0.9638
Epoch 35/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0887 - amazon_score: 0.9110 - acc: 0.9656Epoch 00034: val_loss did not improve

Epoch 00034: reducing learning rate to 6.400000529538374e-08.
1000/1000 [==============================] - 1463s - loss: 0.0887 - amazon_score: 0.9110 - acc: 0.9656 - val_loss: 0.0964 - val_amazon_score: 0.9049 - val_acc: 0.9618
Epoch 36/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0902 - amazon_score: 0.9094 - acc: 0.9647Epoch 00035: val_loss did not improve
1000/1000 [==============================] - 1458s - loss: 0.0902 - amazon_score: 0.9094 - acc: 0.9647 - val_loss: 0.0951 - val_amazon_score: 0.9027 - val_acc: 0.9628
Epoch 37/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0900 - amazon_score: 0.9096 - acc: 0.9650Epoch 00036: val_loss did not improve

Epoch 00036: reducing learning rate to 1.2800001059076749e-08.
1000/1000 [==============================] - 1458s - loss: 0.0901 - amazon_score: 0.9096 - acc: 0.9650 - val_loss: 0.0947 - val_amazon_score: 0.9052 - val_acc: 0.9629
Epoch 38/40
 999/1000 [============================>.] - ETA: 1s - loss: 0.0902 - amazon_score: 0.9095 - acc: 0.9649Epoch 00037: val_loss did not improve
1000/1000 [==============================] - 1458s - loss: 0.0903 - amazon_score: 0.9095 - acc: 0.9649 - val_loss: 0.0962 - val_amazon_score: 0.9063 - val_acc: 0.9621
Epoch 39/40
 147/1000 [===>..........................] - ETA: 1139s - loss: 0.0898 - amazon_score: 0.9105 - acc: 0.9647






Training with val = 1

Epoch 1/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.2179 - amazon_score: 0.7730 - acc: 0.9185Epoch 00000: val_loss improved from inf to 0.39860, saving model to weights-v9-f1.hdf5
1000/1000 [==============================] - 1499s - loss: 0.2178 - amazon_score: 0.7731 - acc: 0.9185 - val_loss: 0.3986 - val_amazon_score: 0.7111 - val_acc: 0.8905
Epoch 2/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1752 - amazon_score: 0.8165 - acc: 0.9308Epoch 00001: val_loss improved from 0.39860 to 0.15978, saving model to weights-v9-f1.hdf5
1000/1000 [==============================] - 1492s - loss: 0.1752 - amazon_score: 0.8165 - acc: 0.9308 - val_loss: 0.1598 - val_amazon_score: 0.8433 - val_acc: 0.9378
Epoch 3/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1494 - amazon_score: 0.8456 - acc: 0.9409Epoch 00003: val_loss did not improve

Epoch 00003: reducing learning rate to 0.00020000000949949026.
1000/1000 [==============================] - 1490s - loss: 0.1495 - amazon_score: 0.8456 - acc: 0.9409 - val_loss: 0.2833 - val_amazon_score: 0.7257 - val_acc: 0.8960
Epoch 5/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1337 - amazon_score: 0.8629 - acc: 0.9466Epoch 00004: val_loss improved from 0.15978 to 0.12711, saving model to weights-v9-f1.hdf5
1000/1000 [==============================] - 1478s - loss: 0.1337 - amazon_score: 0.8629 - acc: 0.9466 - val_loss: 0.1271 - val_amazon_score: 0.8700 - val_acc: 0.9482
Epoch 6/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1280 - amazon_score: 0.8680 - acc: 0.9486Epoch 00005: val_loss did not improve
1000/1000 [==============================] - 1475s - loss: 0.1280 - amazon_score: 0.8680 - acc: 0.9486 - val_loss: 0.1286 - val_amazon_score: 0.8654 - val_acc: 0.9486
Epoch 7/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1260 - amazon_score: 0.8710 - acc: 0.9495Epoch 00006: val_loss improved from 0.12711 to 0.12310, saving model to weights-v9-f1.hdf5
1000/1000 [==============================] - 1478s - loss: 0.1260 - amazon_score: 0.8710 - acc: 0.9495 - val_loss: 0.1231 - val_amazon_score: 0.8742 - val_acc: 0.9514
Epoch 8/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1217 - amazon_score: 0.8756 - acc: 0.9508Epoch 00007: val_loss improved from 0.12310 to 0.11842, saving model to weights-v9-f1.hdf5
1000/1000 [==============================] - 1477s - loss: 0.1217 - amazon_score: 0.8757 - acc: 0.9508 - val_loss: 0.1184 - val_amazon_score: 0.8761 - val_acc: 0.9533
Epoch 9/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1180 - amazon_score: 0.8781 - acc: 0.9531Epoch 00008: val_loss improved from 0.11842 to 0.11683, saving model to weights-v9-f1.hdf5
1000/1000 [==============================] - 1477s - loss: 0.1180 - amazon_score: 0.8781 - acc: 0.9531 - val_loss: 0.1168 - val_amazon_score: 0.8796 - val_acc: 0.9531
Epoch 10/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1158 - amazon_score: 0.8825 - acc: 0.9543Epoch 00009: val_loss improved from 0.11683 to 0.11456, saving model to weights-v9-f1.hdf5
1000/1000 [==============================] - 1477s - loss: 0.1159 - amazon_score: 0.8824 - acc: 0.9543 - val_loss: 0.1146 - val_amazon_score: 0.8833 - val_acc: 0.9540
Epoch 11/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1130 - amazon_score: 0.8849 - acc: 0.9554Epoch 00010: val_loss improved from 0.11456 to 0.11418, saving model to weights-v9-f1.hdf5
1000/1000 [==============================] - 1478s - loss: 0.1131 - amazon_score: 0.8849 - acc: 0.9554 - val_loss: 0.1142 - val_amazon_score: 0.8820 - val_acc: 0.9558
Epoch 12/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1111 - amazon_score: 0.8881 - acc: 0.9562Epoch 00011: val_loss improved from 0.11418 to 0.10845, saving model to weights-v9-f1.hdf5
1000/1000 [==============================] - 1478s - loss: 0.1110 - amazon_score: 0.8881 - acc: 0.9562 - val_loss: 0.1085 - val_amazon_score: 0.8883 - val_acc: 0.9578
Epoch 13/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1095 - amazon_score: 0.8898 - acc: 0.9571Epoch 00012: val_loss did not improve
1000/1000 [==============================] - 1475s - loss: 0.1094 - amazon_score: 0.8899 - acc: 0.9571 - val_loss: 0.1112 - val_amazon_score: 0.8858 - val_acc: 0.9561
Epoch 14/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1070 - amazon_score: 0.8920 - acc: 0.9582Epoch 00013: val_loss did not improve

Epoch 00013: reducing learning rate to 4.0000001899898055e-05.
1000/1000 [==============================] - 1474s - loss: 0.1070 - amazon_score: 0.8920 - acc: 0.9582 - val_loss: 0.1117 - val_amazon_score: 0.8871 - val_acc: 0.9561
Epoch 15/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1017 - amazon_score: 0.8975 - acc: 0.9604Epoch 00014: val_loss improved from 0.10845 to 0.10116, saving model to weights-v9-f1.hdf5
1000/1000 [==============================] - 1477s - loss: 0.1017 - amazon_score: 0.8975 - acc: 0.9604 - val_loss: 0.1012 - val_amazon_score: 0.8968 - val_acc: 0.9601
Epoch 16/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0996 - amazon_score: 0.8995 - acc: 0.9611Epoch 00015: val_loss improved from 0.10116 to 0.09946, saving model to weights-v9-f1.hdf5
1000/1000 [==============================] - 1476s - loss: 0.0996 - amazon_score: 0.8995 - acc: 0.9611 - val_loss: 0.0995 - val_amazon_score: 0.9009 - val_acc: 0.9605
Epoch 17/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0992 - amazon_score: 0.9007 - acc: 0.9612Epoch 00016: val_loss improved from 0.09946 to 0.09681, saving model to weights-v9-f1.hdf5
1000/1000 [==============================] - 1493s - loss: 0.0992 - amazon_score: 0.9007 - acc: 0.9612 - val_loss: 0.0968 - val_amazon_score: 0.8999 - val_acc: 0.9622
Epoch 18/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0984 - amazon_score: 0.9013 - acc: 0.9616Epoch 00017: val_loss did not improve
1000/1000 [==============================] - 1492s - loss: 0.0984 - amazon_score: 0.9014 - acc: 0.9616 - val_loss: 0.0971 - val_amazon_score: 0.9009 - val_acc: 0.9625
Epoch 19/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0976 - amazon_score: 0.9018 - acc: 0.9618Epoch 00018: val_loss did not improve

Epoch 00018: reducing learning rate to 8.000000525498762e-06.
1000/1000 [==============================] - 1496s - loss: 0.0976 - amazon_score: 0.9018 - acc: 0.9618 - val_loss: 0.0986 - val_amazon_score: 0.9005 - val_acc: 0.9609
Epoch 20/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0962 - amazon_score: 0.9041 - acc: 0.9624Epoch 00019: val_loss did not improve

Epoch 00019: reducing learning rate to 1.6000001778593287e-06.
1000/1000 [==============================] - 1495s - loss: 0.0962 - amazon_score: 0.9041 - acc: 0.9624 - val_loss: 0.0989 - val_amazon_score: 0.8994 - val_acc: 0.9614
Epoch 21/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0963 - amazon_score: 0.9034 - acc: 0.9624Epoch 00020: val_loss improved from 0.09681 to 0.09563, saving model to weights-v9-f1.hdf5
1000/1000 [==============================] - 1501s - loss: 0.0963 - amazon_score: 0.9034 - acc: 0.9624 - val_loss: 0.0956 - val_amazon_score: 0.9025 - val_acc: 0.9629
Epoch 22/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0949 - amazon_score: 0.9048 - acc: 0.9632Epoch 00021: val_loss did not improve
1000/1000 [==============================] - 1500s - loss: 0.0949 - amazon_score: 0.9048 - acc: 0.9632 - val_loss: 0.0988 - val_amazon_score: 0.8985 - val_acc: 0.9621
Epoch 23/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0959 - amazon_score: 0.9045 - acc: 0.9626Epoch 00022: val_loss did not improve

Epoch 00022: reducing learning rate to 3.200000264769187e-07.
1000/1000 [==============================] - 1495s - loss: 0.0959 - amazon_score: 0.9044 - acc: 0.9626 - val_loss: 0.0972 - val_amazon_score: 0.9002 - val_acc: 0.9617
Epoch 24/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0968 - amazon_score: 0.9034 - acc: 0.9621Epoch 00023: val_loss did not improve

Epoch 00023: reducing learning rate to 1e-07.
1000/1000 [==============================] - 1496s - loss: 0.0968 - amazon_score: 0.9034 - acc: 0.9621 - val_loss: 0.0990 - val_amazon_score: 0.8968 - val_acc: 0.9613
Epoch 25/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0959 - amazon_score: 0.9036 - acc: 0.9626Epoch 00024: val_loss did not improve
1000/1000 [==============================] - 1488s - loss: 0.0959 - amazon_score: 0.9036 - acc: 0.9626 - val_loss: 0.0978 - val_amazon_score: 0.9007 - val_acc: 0.9620
Epoch 26/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0967 - amazon_score: 0.9032 - acc: 0.9621Epoch 00025: val_loss did not improve
1000/1000 [==============================] - 1475s - loss: 0.0967 - amazon_score: 0.9032 - acc: 0.9621 - val_loss: 0.0995 - val_amazon_score: 0.8995 - val_acc: 0.9607
Epoch 27/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0967 - amazon_score: 0.9036 - acc: 0.9622Epoch 00026: val_loss did not improve
1000/1000 [==============================] - 1474s - loss: 0.0967 - amazon_score: 0.9036 - acc: 0.9622 - val_loss: 0.0959 - val_amazon_score: 0.9026 - val_acc: 0.9625
Epoch 28/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0960 - amazon_score: 0.9037 - acc: 0.9625Epoch 00027: val_loss did not improve
1000/1000 [==============================] - 1473s - loss: 0.0960 - amazon_score: 0.9037 - acc: 0.9625 - val_loss: 0.0964 - val_amazon_score: 0.9012 - val_acc: 0.9623
Epoch 29/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0970 - amazon_score: 0.9031 - acc: 0.9620Epoch 00028: val_loss improved from 0.09563 to 0.09560, saving model to weights-v9-f1.hdf5
1000/1000 [==============================] - 1476s - loss: 0.0970 - amazon_score: 0.9031 - acc: 0.9620 - val_loss: 0.0956 - val_amazon_score: 0.9010 - val_acc: 0.9629
Epoch 30/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0943 - amazon_score: 0.9059 - acc: 0.9633Epoch 00029: val_loss improved from 0.09560 to 0.09558, saving model to weights-v9-f1.hdf5
1000/1000 [==============================] - 1476s - loss: 0.0943 - amazon_score: 0.9059 - acc: 0.9633 - val_loss: 0.0956 - val_amazon_score: 0.9035 - val_acc: 0.9626

Training with val = 2

Epoch 1/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.2206 - amazon_score: 0.7687 - acc: 0.9183Epoch 00000: val_loss improved from inf to 0.81078, saving model to weights-v9-f2.hdf5
1000/1000 [==============================] - 1506s - loss: 0.2206 - amazon_score: 0.7687 - acc: 0.9183 - val_loss: 0.8108 - val_amazon_score: 0.6793 - val_acc: 0.8595
Epoch 2/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1728 - amazon_score: 0.8195 - acc: 0.9318Epoch 00001: val_loss improved from 0.81078 to 0.24855, saving model to weights-v9-f2.hdf5
1000/1000 [==============================] - 1474s - loss: 0.1728 - amazon_score: 0.8194 - acc: 0.9318 - val_loss: 0.2486 - val_amazon_score: 0.8135 - val_acc: 0.9230
Epoch 3/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1567 - amazon_score: 0.8374 - acc: 0.9380Epoch 00002: val_loss did not improve
1000/1000 [==============================] - 1472s - loss: 0.1567 - amazon_score: 0.8374 - acc: 0.9380 - val_loss: 0.3000 - val_amazon_score: 0.7283 - val_acc: 0.8838
Epoch 4/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1476 - amazon_score: 0.8474 - acc: 0.9414Epoch 00003: val_loss improved from 0.24855 to 0.14661, saving model to weights-v9-f2.hdf5
1000/1000 [==============================] - 1473s - loss: 0.1476 - amazon_score: 0.8474 - acc: 0.9414 - val_loss: 0.1466 - val_amazon_score: 0.8478 - val_acc: 0.9419
Epoch 5/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1406 - amazon_score: 0.8545 - acc: 0.9443Epoch 00004: val_loss improved from 0.14661 to 0.14377, saving model to weights-v9-f2.hdf5
1000/1000 [==============================] - 1474s - loss: 0.1406 - amazon_score: 0.8545 - acc: 0.9443 - val_loss: 0.1438 - val_amazon_score: 0.8564 - val_acc: 0.9449
Epoch 6/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1337 - amazon_score: 0.8633 - acc: 0.9471Epoch 00005: val_loss improved from 0.14377 to 0.14006, saving model to weights-v9-f2.hdf5
1000/1000 [==============================] - 1474s - loss: 0.1337 - amazon_score: 0.8633 - acc: 0.9471 - val_loss: 0.1401 - val_amazon_score: 0.8537 - val_acc: 0.9472
Epoch 7/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1283 - amazon_score: 0.8697 - acc: 0.9493Epoch 00006: val_loss improved from 0.14006 to 0.11693, saving model to weights-v9-f2.hdf5
1000/1000 [==============================] - 1480s - loss: 0.1283 - amazon_score: 0.8697 - acc: 0.9493 - val_loss: 0.1169 - val_amazon_score: 0.8771 - val_acc: 0.9548
Epoch 8/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1231 - amazon_score: 0.8771 - acc: 0.9514Epoch 00007: val_loss did not improve
1000/1000 [==============================] - 1494s - loss: 0.1230 - amazon_score: 0.8772 - acc: 0.9514 - val_loss: 0.1231 - val_amazon_score: 0.8745 - val_acc: 0.9529
Epoch 9/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1198 - amazon_score: 0.8796 - acc: 0.9528Epoch 00008: val_loss did not improve

Epoch 00008: reducing learning rate to 0.00020000000949949026.
1000/1000 [==============================] - 1480s - loss: 0.1197 - amazon_score: 0.8796 - acc: 0.9528 - val_loss: 0.1327 - val_amazon_score: 0.8584 - val_acc: 0.9529
Epoch 10/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1072 - amazon_score: 0.8921 - acc: 0.9576Epoch 00009: val_loss improved from 0.11693 to 0.10532, saving model to weights-v9-f2.hdf5
1000/1000 [==============================] - 1479s - loss: 0.1072 - amazon_score: 0.8921 - acc: 0.9576 - val_loss: 0.1053 - val_amazon_score: 0.8936 - val_acc: 0.9591
Epoch 11/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1036 - amazon_score: 0.8961 - acc: 0.9591Epoch 00010: val_loss improved from 0.10532 to 0.10075, saving model to weights-v9-f2.hdf5
1000/1000 [==============================] - 1480s - loss: 0.1036 - amazon_score: 0.8961 - acc: 0.9591 - val_loss: 0.1008 - val_amazon_score: 0.8974 - val_acc: 0.9605
Epoch 12/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1028 - amazon_score: 0.8973 - acc: 0.9597Epoch 00011: val_loss improved from 0.10075 to 0.09995, saving model to weights-v9-f2.hdf5
1000/1000 [==============================] - 1500s - loss: 0.1029 - amazon_score: 0.8973 - acc: 0.9597 - val_loss: 0.1000 - val_amazon_score: 0.8972 - val_acc: 0.9612
Epoch 13/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1013 - amazon_score: 0.8992 - acc: 0.9598Epoch 00012: val_loss did not improve
1000/1000 [==============================] - 1500s - loss: 0.1013 - amazon_score: 0.8992 - acc: 0.9598 - val_loss: 0.1010 - val_amazon_score: 0.8933 - val_acc: 0.9613
Epoch 14/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1011 - amazon_score: 0.8986 - acc: 0.9602Epoch 00013: val_loss did not improve

Epoch 00013: reducing learning rate to 4.0000001899898055e-05.
1000/1000 [==============================] - 1492s - loss: 0.1011 - amazon_score: 0.8986 - acc: 0.9602 - val_loss: 0.1009 - val_amazon_score: 0.8970 - val_acc: 0.9609
Epoch 15/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0962 - amazon_score: 0.9045 - acc: 0.9624Epoch 00014: val_loss improved from 0.09995 to 0.09608, saving model to weights-v9-f2.hdf5
1000/1000 [==============================] - 1501s - loss: 0.0962 - amazon_score: 0.9045 - acc: 0.9623 - val_loss: 0.0961 - val_amazon_score: 0.9020 - val_acc: 0.9632
Epoch 16/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0943 - amazon_score: 0.9071 - acc: 0.9629Epoch 00015: val_loss did not improve
1000/1000 [==============================] - 1498s - loss: 0.0943 - amazon_score: 0.9071 - acc: 0.9629 - val_loss: 0.0965 - val_amazon_score: 0.8988 - val_acc: 0.9626
Epoch 17/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0962 - amazon_score: 0.9047 - acc: 0.9623Epoch 00016: val_loss did not improve

Epoch 00016: reducing learning rate to 8.000000525498762e-06.
1000/1000 [==============================] - 1494s - loss: 0.0962 - amazon_score: 0.9047 - acc: 0.9623 - val_loss: 0.0975 - val_amazon_score: 0.8993 - val_acc: 0.9625
Epoch 18/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0938 - amazon_score: 0.9068 - acc: 0.9629Epoch 00017: val_loss improved from 0.09608 to 0.09567, saving model to weights-v9-f2.hdf5
1000/1000 [==============================] - 1499s - loss: 0.0938 - amazon_score: 0.9068 - acc: 0.9629 - val_loss: 0.0957 - val_amazon_score: 0.9023 - val_acc: 0.9628
Epoch 19/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0942 - amazon_score: 0.9058 - acc: 0.9630Epoch 00018: val_loss did not improve
1000/1000 [==============================] - 1503s - loss: 0.0942 - amazon_score: 0.9059 - acc: 0.9630 - val_loss: 0.0975 - val_amazon_score: 0.9001 - val_acc: 0.9622
Epoch 20/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0930 - amazon_score: 0.9066 - acc: 0.9638Epoch 00019: val_loss improved from 0.09567 to 0.09517, saving model to weights-v9-f2.hdf5
1000/1000 [==============================] - 1502s - loss: 0.0930 - amazon_score: 0.9066 - acc: 0.9638 - val_loss: 0.0952 - val_amazon_score: 0.9019 - val_acc: 0.9629
Epoch 21/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0942 - amazon_score: 0.9070 - acc: 0.9628Epoch 00020: val_loss did not improve
1000/1000 [==============================] - 1492s - loss: 0.0942 - amazon_score: 0.9069 - acc: 0.9628 - val_loss: 0.0963 - val_amazon_score: 0.8978 - val_acc: 0.9627
Epoch 22/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0931 - amazon_score: 0.9075 - acc: 0.9635Epoch 00021: val_loss did not improve

Epoch 00021: reducing learning rate to 1.6000001778593287e-06.
1000/1000 [==============================] - 1479s - loss: 0.0931 - amazon_score: 0.9075 - acc: 0.9635 - val_loss: 0.0968 - val_amazon_score: 0.9003 - val_acc: 0.9629
Epoch 23/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0938 - amazon_score: 0.9059 - acc: 0.9633Epoch 00022: val_loss improved from 0.09517 to 0.09185, saving model to weights-v9-f2.hdf5
1000/1000 [==============================] - 1481s - loss: 0.0938 - amazon_score: 0.9059 - acc: 0.9633 - val_loss: 0.0919 - val_amazon_score: 0.9044 - val_acc: 0.9639
Epoch 24/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0927 - amazon_score: 0.9083 - acc: 0.9636Epoch 00023: val_loss did not improve
1000/1000 [==============================] - 1479s - loss: 0.0926 - amazon_score: 0.9083 - acc: 0.9636 - val_loss: 0.0935 - val_amazon_score: 0.9037 - val_acc: 0.9633
Epoch 25/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0931 - amazon_score: 0.9076 - acc: 0.9639Epoch 00024: val_loss did not improve

Epoch 00024: reducing learning rate to 3.200000264769187e-07.
1000/1000 [==============================] - 1479s - loss: 0.0931 - amazon_score: 0.9076 - acc: 0.9639 - val_loss: 0.0949 - val_amazon_score: 0.9039 - val_acc: 0.9631
Epoch 26/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0936 - amazon_score: 0.9070 - acc: 0.9633Epoch 00025: val_loss did not improve

Epoch 00025: reducing learning rate to 1e-07.
1000/1000 [==============================] - 1479s - loss: 0.0936 - amazon_score: 0.9071 - acc: 0.9633 - val_loss: 0.0966 - val_amazon_score: 0.9017 - val_acc: 0.9633
Epoch 27/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0938 - amazon_score: 0.9061 - acc: 0.9630Epoch 00026: val_loss did not improve
1000/1000 [==============================] - 1479s - loss: 0.0939 - amazon_score: 0.9060 - acc: 0.9630 - val_loss: 0.0970 - val_amazon_score: 0.9019 - val_acc: 0.9634
Epoch 28/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0940 - amazon_score: 0.9065 - acc: 0.9631Epoch 00027: val_loss did not improve
1000/1000 [==============================] - 1479s - loss: 0.0941 - amazon_score: 0.9065 - acc: 0.9631 - val_loss: 0.0932 - val_amazon_score: 0.9041 - val_acc: 0.9637
Epoch 29/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0944 - amazon_score: 0.9064 - acc: 0.9628Epoch 00028: val_loss did not improve
1000/1000 [==============================] - 1480s - loss: 0.0944 - amazon_score: 0.9064 - acc: 0.9628 - val_loss: 0.0943 - val_amazon_score: 0.9044 - val_acc: 0.9639
Epoch 30/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0938 - amazon_score: 0.9069 - acc: 0.9632Epoch 00029: val_loss did not improve
1000/1000 [==============================] - 1481s - loss: 0.0939 - amazon_score: 0.9069 - acc: 0.9632 - val_loss: 0.0933 - val_amazon_score: 0.9048 - val_acc: 0.9645

Training with val = 3

Epoch 1/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.2180 - amazon_score: 0.7668 - acc: 0.9192Epoch 00000: val_loss improved from inf to 0.19921, saving model to weights-v9-f3.hdf5
1000/1000 [==============================] - 1519s - loss: 0.2180 - amazon_score: 0.7667 - acc: 0.9192 - val_loss: 0.1992 - val_amazon_score: 0.7880 - val_acc: 0.9254
Epoch 2/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1734 - amazon_score: 0.8174 - acc: 0.9326Epoch 00001: val_loss did not improve
1000/1000 [==============================] - 1475s - loss: 0.1733 - amazon_score: 0.8173 - acc: 0.9326 - val_loss: 0.3036 - val_amazon_score: 0.7780 - val_acc: 0.9213
Epoch 3/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1577 - amazon_score: 0.8353 - acc: 0.9384Epoch 00002: val_loss did not improve

Epoch 00002: reducing learning rate to 0.00020000000949949026.
1000/1000 [==============================] - 1477s - loss: 0.1577 - amazon_score: 0.8353 - acc: 0.9385 - val_loss: 0.6189 - val_amazon_score: 0.7872 - val_acc: 0.9061
Epoch 4/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1371 - amazon_score: 0.8589 - acc: 0.9457Epoch 00003: val_loss improved from 0.19921 to 0.14227, saving model to weights-v9-f3.hdf5
1000/1000 [==============================] - 1478s - loss: 0.1372 - amazon_score: 0.8588 - acc: 0.9457 - val_loss: 0.1423 - val_amazon_score: 0.8617 - val_acc: 0.9467
Epoch 5/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1314 - amazon_score: 0.8645 - acc: 0.9479Epoch 00004: val_loss did not improve
1000/1000 [==============================] - 1475s - loss: 0.1314 - amazon_score: 0.8645 - acc: 0.9479 - val_loss: 0.1701 - val_amazon_score: 0.8640 - val_acc: 0.9459
Epoch 6/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1286 - amazon_score: 0.8667 - acc: 0.9489Epoch 00005: val_loss did not improve

Epoch 00005: reducing learning rate to 4.0000001899898055e-05.
1000/1000 [==============================] - 1478s - loss: 0.1286 - amazon_score: 0.8667 - acc: 0.9489 - val_loss: 0.1612 - val_amazon_score: 0.8638 - val_acc: 0.9472
Epoch 7/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1194 - amazon_score: 0.8763 - acc: 0.9522Epoch 00006: val_loss did not improve

Epoch 00006: reducing learning rate to 8.000000525498762e-06.
1000/1000 [==============================] - 1466s - loss: 0.1194 - amazon_score: 0.8763 - acc: 0.9522 - val_loss: 0.1436 - val_amazon_score: 0.8713 - val_acc: 0.9499
Epoch 8/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1182 - amazon_score: 0.8777 - acc: 0.9531Epoch 00007: val_loss improved from 0.14227 to 0.14087, saving model to weights-v9-f3.hdf5
1000/1000 [==============================] - 1465s - loss: 0.1182 - amazon_score: 0.8777 - acc: 0.9531 - val_loss: 0.1409 - val_amazon_score: 0.8750 - val_acc: 0.9521
Epoch 9/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1172 - amazon_score: 0.8770 - acc: 0.9532Epoch 00008: val_loss did not improve
1000/1000 [==============================] - 1461s - loss: 0.1172 - amazon_score: 0.8771 - acc: 0.9532 - val_loss: 0.1421 - val_amazon_score: 0.8742 - val_acc: 0.9520
Epoch 10/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1184 - amazon_score: 0.8771 - acc: 0.9526Epoch 00009: val_loss did not improve

Epoch 00009: reducing learning rate to 1.6000001778593287e-06.
1000/1000 [==============================] - 1459s - loss: 0.1184 - amazon_score: 0.8771 - acc: 0.9526 - val_loss: 0.1539 - val_amazon_score: 0.8706 - val_acc: 0.9499
Epoch 11/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1188 - amazon_score: 0.8770 - acc: 0.9526Epoch 00010: val_loss did not improve

Epoch 00010: reducing learning rate to 3.200000264769187e-07.
1000/1000 [==============================] - 1459s - loss: 0.1188 - amazon_score: 0.8770 - acc: 0.9526 - val_loss: 0.1492 - val_amazon_score: 0.8719 - val_acc: 0.9513
Epoch 12/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1180 - amazon_score: 0.8779 - acc: 0.9529Epoch 00011: val_loss did not improve

Epoch 00011: reducing learning rate to 1e-07.
1000/1000 [==============================] - 1460s - loss: 0.1180 - amazon_score: 0.8779 - acc: 0.9529 - val_loss: 0.1592 - val_amazon_score: 0.8679 - val_acc: 0.9490
Epoch 13/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1175 - amazon_score: 0.8786 - acc: 0.9532Epoch 00012: val_loss did not improve
1000/1000 [==============================] - 1461s - loss: 0.1174 - amazon_score: 0.8786 - acc: 0.9532 - val_loss: 0.1545 - val_amazon_score: 0.8674 - val_acc: 0.9500
Epoch 14/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1170 - amazon_score: 0.8798 - acc: 0.9531Epoch 00013: val_loss did not improve
1000/1000 [==============================] - 1461s - loss: 0.1170 - amazon_score: 0.8798 - acc: 0.9531 - val_loss: 0.1503 - val_amazon_score: 0.8692 - val_acc: 0.9502
Epoch 15/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1164 - amazon_score: 0.8791 - acc: 0.9535Epoch 00014: val_loss did not improve
1000/1000 [==============================] - 1469s - loss: 0.1164 - amazon_score: 0.8791 - acc: 0.9535 - val_loss: 0.1516 - val_amazon_score: 0.8701 - val_acc: 0.9507
Epoch 16/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1175 - amazon_score: 0.8775 - acc: 0.9533Epoch 00015: val_loss did not improve
1000/1000 [==============================] - 1461s - loss: 0.1175 - amazon_score: 0.8775 - acc: 0.9533 - val_loss: 0.1484 - val_amazon_score: 0.8721 - val_acc: 0.9499
Epoch 17/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1176 - amazon_score: 0.8766 - acc: 0.9530Epoch 00016: val_loss did not improve
1000/1000 [==============================] - 1461s - loss: 0.1177 - amazon_score: 0.8766 - acc: 0.9530 - val_loss: 0.1528 - val_amazon_score: 0.8663 - val_acc: 0.9492
Epoch 18/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1183 - amazon_score: 0.8769 - acc: 0.9529Epoch 00017: val_loss did not improve
1000/1000 [==============================] - 1461s - loss: 0.1182 - amazon_score: 0.8769 - acc: 0.9529 - val_loss: 0.1555 - val_amazon_score: 0.8696 - val_acc: 0.9499
Epoch 19/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1159 - amazon_score: 0.8793 - acc: 0.9538Epoch 00018: val_loss did not improve
1000/1000 [==============================] - 1477s - loss: 0.1159 - amazon_score: 0.8794 - acc: 0.9538 - val_loss: 0.1600 - val_amazon_score: 0.8687 - val_acc: 0.9500
Epoch 20/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1171 - amazon_score: 0.8794 - acc: 0.9534Epoch 00019: val_loss did not improve
1000/1000 [==============================] - 1466s - loss: 0.1171 - amazon_score: 0.8794 - acc: 0.9534 - val_loss: 0.1559 - val_amazon_score: 0.8691 - val_acc: 0.9494
Epoch 21/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1176 - amazon_score: 0.8783 - acc: 0.9529Epoch 00020: val_loss did not improve
1000/1000 [==============================] - 1472s - loss: 0.1177 - amazon_score: 0.8783 - acc: 0.9529 - val_loss: 0.1603 - val_amazon_score: 0.8681 - val_acc: 0.9501
Epoch 22/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1172 - amazon_score: 0.8778 - acc: 0.9531Epoch 00021: val_loss did not improve
1000/1000 [==============================] - 1474s - loss: 0.1173 - amazon_score: 0.8778 - acc: 0.9531 - val_loss: 0.1623 - val_amazon_score: 0.8675 - val_acc: 0.9483
Epoch 23/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1181 - amazon_score: 0.8781 - acc: 0.9526Epoch 00022: val_loss did not improve
1000/1000 [==============================] - 1468s - loss: 0.1180 - amazon_score: 0.8781 - acc: 0.9526 - val_loss: 0.1562 - val_amazon_score: 0.8673 - val_acc: 0.9498
Epoch 24/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1174 - amazon_score: 0.8782 - acc: 0.9528Epoch 00023: val_loss did not improve
1000/1000 [==============================] - 1478s - loss: 0.1174 - amazon_score: 0.8782 - acc: 0.9528 - val_loss: 0.1522 - val_amazon_score: 0.8708 - val_acc: 0.9510
Epoch 25/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1173 - amazon_score: 0.8781 - acc: 0.9531Epoch 00024: val_loss did not improve
1000/1000 [==============================] - 1483s - loss: 0.1174 - amazon_score: 0.8780 - acc: 0.9531 - val_loss: 0.1484 - val_amazon_score: 0.8700 - val_acc: 0.9512
Epoch 26/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1179 - amazon_score: 0.8790 - acc: 0.9530Epoch 00025: val_loss did not improve
1000/1000 [==============================] - 1483s - loss: 0.1179 - amazon_score: 0.8790 - acc: 0.9530 - val_loss: 0.1575 - val_amazon_score: 0.8668 - val_acc: 0.9490
Epoch 27/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1179 - amazon_score: 0.8766 - acc: 0.9530Epoch 00026: val_loss did not improve
1000/1000 [==============================] - 1482s - loss: 0.1180 - amazon_score: 0.8766 - acc: 0.9530 - val_loss: 0.1564 - val_amazon_score: 0.8678 - val_acc: 0.9487
Epoch 28/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1165 - amazon_score: 0.8783 - acc: 0.9533Epoch 00027: val_loss did not improve
1000/1000 [==============================] - 1478s - loss: 0.1165 - amazon_score: 0.8783 - acc: 0.9533 - val_loss: 0.1490 - val_amazon_score: 0.8708 - val_acc: 0.9509
Epoch 29/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1176 - amazon_score: 0.8782 - acc: 0.9529Epoch 00028: val_loss did not improve
1000/1000 [==============================] - 1475s - loss: 0.1176 - amazon_score: 0.8782 - acc: 0.9529 - val_loss: 0.1499 - val_amazon_score: 0.8719 - val_acc: 0.9500
Epoch 30/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1173 - amazon_score: 0.8773 - acc: 0.9530Epoch 00029: val_loss did not improve
1000/1000 [==============================] - 1458s - loss: 0.1173 - amazon_score: 0.8773 - acc: 0.9530 - val_loss: 0.1451 - val_amazon_score: 0.8730 - val_acc: 0.9518






Training with val = 4

Epoch 1/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.2092 - amazon_score: 0.7821 - acc: 0.9207Epoch 00000: val_loss improved from inf to 0.20025, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1641s - loss: 0.2091 - amazon_score: 0.7822 - acc: 0.9207 - val_loss: 0.2002 - val_amazon_score: 0.8118 - val_acc: 0.9269
Epoch 2/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1644 - amazon_score: 0.8295 - acc: 0.9353Epoch 00001: val_loss improved from 0.20025 to 0.18755, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1550s - loss: 0.1644 - amazon_score: 0.8296 - acc: 0.9353 - val_loss: 0.1875 - val_amazon_score: 0.8207 - val_acc: 0.9315
Epoch 3/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1519 - amazon_score: 0.8429 - acc: 0.9404Epoch 00002: val_loss did not improve
1000/1000 [==============================] - 1527s - loss: 0.1519 - amazon_score: 0.8429 - acc: 0.9404 - val_loss: 0.1995 - val_amazon_score: 0.8405 - val_acc: 0.9347
Epoch 4/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1433 - amazon_score: 0.8528 - acc: 0.9433Epoch 00003: val_loss improved from 0.18755 to 0.14149, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1549s - loss: 0.1433 - amazon_score: 0.8528 - acc: 0.9433 - val_loss: 0.1415 - val_amazon_score: 0.8506 - val_acc: 0.9455
Epoch 5/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1382 - amazon_score: 0.8579 - acc: 0.9456Epoch 00004: val_loss improved from 0.14149 to 0.13461, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1547s - loss: 0.1382 - amazon_score: 0.8579 - acc: 0.9456 - val_loss: 0.1346 - val_amazon_score: 0.8587 - val_acc: 0.9466
Epoch 6/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1320 - amazon_score: 0.8654 - acc: 0.9483Epoch 00005: val_loss did not improve
1000/1000 [==============================] - 1526s - loss: 0.1320 - amazon_score: 0.8654 - acc: 0.9483 - val_loss: 0.1810 - val_amazon_score: 0.8288 - val_acc: 0.9375
Epoch 7/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1269 - amazon_score: 0.8705 - acc: 0.9504Epoch 00006: val_loss improved from 0.13461 to 0.13369, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1545s - loss: 0.1270 - amazon_score: 0.8704 - acc: 0.9504 - val_loss: 0.1337 - val_amazon_score: 0.8649 - val_acc: 0.9494
Epoch 8/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1229 - amazon_score: 0.8752 - acc: 0.9522Epoch 00007: val_loss did not improve
1000/1000 [==============================] - 1524s - loss: 0.1229 - amazon_score: 0.8752 - acc: 0.9522 - val_loss: 0.1994 - val_amazon_score: 0.8194 - val_acc: 0.9236
Epoch 9/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1219 - amazon_score: 0.8777 - acc: 0.9524Epoch 00008: val_loss improved from 0.13369 to 0.12833, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1540s - loss: 0.1219 - amazon_score: 0.8777 - acc: 0.9524 - val_loss: 0.1283 - val_amazon_score: 0.8664 - val_acc: 0.9495
Epoch 10/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1159 - amazon_score: 0.8839 - acc: 0.9548Epoch 00009: val_loss improved from 0.12833 to 0.12372, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1538s - loss: 0.1159 - amazon_score: 0.8839 - acc: 0.9548 - val_loss: 0.1237 - val_amazon_score: 0.8742 - val_acc: 0.9536
Epoch 11/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1128 - amazon_score: 0.8865 - acc: 0.9561Epoch 00010: val_loss improved from 0.12372 to 0.11892, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1535s - loss: 0.1128 - amazon_score: 0.8865 - acc: 0.9561 - val_loss: 0.1189 - val_amazon_score: 0.8786 - val_acc: 0.9534
Epoch 12/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1113 - amazon_score: 0.8890 - acc: 0.9570Epoch 00011: val_loss improved from 0.11892 to 0.11121, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1536s - loss: 0.1113 - amazon_score: 0.8890 - acc: 0.9570 - val_loss: 0.1112 - val_amazon_score: 0.8895 - val_acc: 0.9576
Epoch 13/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1088 - amazon_score: 0.8913 - acc: 0.9576Epoch 00012: val_loss did not improve
1000/1000 [==============================] - 1523s - loss: 0.1088 - amazon_score: 0.8913 - acc: 0.9576 - val_loss: 0.1342 - val_amazon_score: 0.8656 - val_acc: 0.9530
Epoch 14/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1061 - amazon_score: 0.8937 - acc: 0.9587Epoch 00013: val_loss improved from 0.11121 to 0.10365, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1531s - loss: 0.1061 - amazon_score: 0.8937 - acc: 0.9587 - val_loss: 0.1037 - val_amazon_score: 0.8956 - val_acc: 0.9592
Epoch 15/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1033 - amazon_score: 0.8968 - acc: 0.9600Epoch 00014: val_loss did not improve
1000/1000 [==============================] - 1522s - loss: 0.1033 - amazon_score: 0.8968 - acc: 0.9600 - val_loss: 0.1146 - val_amazon_score: 0.8892 - val_acc: 0.9591
Epoch 16/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.1012 - amazon_score: 0.8987 - acc: 0.9606Epoch 00015: val_loss did not improve

Epoch 00015: reducing learning rate to 0.00020000000949949026.
1000/1000 [==============================] - 1522s - loss: 0.1012 - amazon_score: 0.8986 - acc: 0.9606 - val_loss: 0.3224 - val_amazon_score: 0.6778 - val_acc: 0.8887
Epoch 17/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0957 - amazon_score: 0.9053 - acc: 0.9627Epoch 00016: val_loss improved from 0.10365 to 0.09468, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1512s - loss: 0.0957 - amazon_score: 0.9053 - acc: 0.9627 - val_loss: 0.0947 - val_amazon_score: 0.9041 - val_acc: 0.9636
Epoch 18/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0931 - amazon_score: 0.9069 - acc: 0.9638Epoch 00017: val_loss did not improve
1000/1000 [==============================] - 1508s - loss: 0.0931 - amazon_score: 0.9068 - acc: 0.9638 - val_loss: 0.0962 - val_amazon_score: 0.9021 - val_acc: 0.9629
Epoch 19/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0927 - amazon_score: 0.9071 - acc: 0.9639Epoch 00018: val_loss improved from 0.09468 to 0.09254, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1512s - loss: 0.0927 - amazon_score: 0.9071 - acc: 0.9639 - val_loss: 0.0925 - val_amazon_score: 0.9065 - val_acc: 0.9644
Epoch 20/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0913 - amazon_score: 0.9088 - acc: 0.9646Epoch 00019: val_loss improved from 0.09254 to 0.09128, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1511s - loss: 0.0913 - amazon_score: 0.9088 - acc: 0.9646 - val_loss: 0.0913 - val_amazon_score: 0.9082 - val_acc: 0.9642
Epoch 21/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0920 - amazon_score: 0.9097 - acc: 0.9644Epoch 00020: val_loss did not improve
1000/1000 [==============================] - 1508s - loss: 0.0920 - amazon_score: 0.9097 - acc: 0.9644 - val_loss: 0.0921 - val_amazon_score: 0.9051 - val_acc: 0.9636
Epoch 22/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0900 - amazon_score: 0.9099 - acc: 0.9652Epoch 00021: val_loss did not improve

Epoch 00021: reducing learning rate to 4.0000001899898055e-05.
1000/1000 [==============================] - 1507s - loss: 0.0900 - amazon_score: 0.9099 - acc: 0.9651 - val_loss: 0.0933 - val_amazon_score: 0.9043 - val_acc: 0.9632
Epoch 23/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0888 - amazon_score: 0.9122 - acc: 0.9654Epoch 00022: val_loss did not improve

Epoch 00022: reducing learning rate to 8.000000525498762e-06.
1000/1000 [==============================] - 1508s - loss: 0.0888 - amazon_score: 0.9121 - acc: 0.9654 - val_loss: 0.0917 - val_amazon_score: 0.9080 - val_acc: 0.9638
Epoch 24/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0879 - amazon_score: 0.9121 - acc: 0.9660Epoch 00023: val_loss improved from 0.09128 to 0.09069, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1512s - loss: 0.0880 - amazon_score: 0.9120 - acc: 0.9660 - val_loss: 0.0907 - val_amazon_score: 0.9092 - val_acc: 0.9638
Epoch 25/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0881 - amazon_score: 0.9126 - acc: 0.9658Epoch 00024: val_loss improved from 0.09069 to 0.08929, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1512s - loss: 0.0881 - amazon_score: 0.9126 - acc: 0.9658 - val_loss: 0.0893 - val_amazon_score: 0.9081 - val_acc: 0.9649
Epoch 26/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0862 - amazon_score: 0.9138 - acc: 0.9664Epoch 00025: val_loss did not improve
1000/1000 [==============================] - 1509s - loss: 0.0862 - amazon_score: 0.9138 - acc: 0.9664 - val_loss: 0.0899 - val_amazon_score: 0.9088 - val_acc: 0.9648
Epoch 27/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0876 - amazon_score: 0.9130 - acc: 0.9655Epoch 00026: val_loss did not improve

Epoch 00026: reducing learning rate to 1.6000001778593287e-06.
1000/1000 [==============================] - 1509s - loss: 0.0876 - amazon_score: 0.9130 - acc: 0.9655 - val_loss: 0.0896 - val_amazon_score: 0.9096 - val_acc: 0.9651
Epoch 28/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0873 - amazon_score: 0.9129 - acc: 0.9659Epoch 00027: val_loss did not improve

Epoch 00027: reducing learning rate to 3.200000264769187e-07.
1000/1000 [==============================] - 1509s - loss: 0.0873 - amazon_score: 0.9129 - acc: 0.9659 - val_loss: 0.0902 - val_amazon_score: 0.9084 - val_acc: 0.9650
Epoch 29/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0878 - amazon_score: 0.9125 - acc: 0.9660Epoch 00028: val_loss improved from 0.08929 to 0.08704, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1513s - loss: 0.0878 - amazon_score: 0.9125 - acc: 0.9660 - val_loss: 0.0870 - val_amazon_score: 0.9101 - val_acc: 0.9663
Epoch 30/30
 999/1000 [============================>.] - ETA: 1s - loss: 0.0884 - amazon_score: 0.9116 - acc: 0.9655Epoch 00029: val_loss improved from 0.08704 to 0.08688, saving model to weights-v9-f4.hdf5
1000/1000 [==============================] - 1513s - loss: 0.0884 - amazon_score: 0.9116 - acc: 0.9655 - val_loss: 0.0869 - val_amazon_score: 0.9105 - val_acc: 0.9664