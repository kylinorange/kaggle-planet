Training with val = 4

Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5
86409216/87910968 [============================>.] - ETA: 0sEpoch 1/1
1000/1000 [==============================] - 435s - loss: 0.1725 - amazon_score: 0.8261 - acc: 0.9363 - val_loss: 0.1471 - val_amazon_score: 0.8516 - val_acc: 0.9446
Epoch 2/2
1000/1000 [==============================] - 479s - loss: 0.1261 - amazon_score: 0.8730 - acc: 0.9522 - val_loss: 0.1174 - val_amazon_score: 0.8763 - val_acc: 0.9548
Epoch 3/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.1038 - amazon_score: 0.8975 - acc: 0.9601Epoch 00002: val_loss improved from inf to 0.09955, saving model to weights-v12-f4.hdf5
1000/1000 [==============================] - 665s - loss: 0.1038 - amazon_score: 0.8975 - acc: 0.9602 - val_loss: 0.0995 - val_amazon_score: 0.9025 - val_acc: 0.9626
Epoch 4/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0935 - amazon_score: 0.9068 - acc: 0.9642Epoch 00003: val_loss improved from 0.09955 to 0.09555, saving model to weights-v12-f4.hdf5
1000/1000 [==============================] - 644s - loss: 0.0935 - amazon_score: 0.9068 - acc: 0.9642 - val_loss: 0.0955 - val_amazon_score: 0.9037 - val_acc: 0.9635
Epoch 5/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0889 - amazon_score: 0.9125 - acc: 0.9657Epoch 00004: val_loss improved from 0.09555 to 0.09408, saving model to weights-v12-f4.hdf5
1000/1000 [==============================] - 644s - loss: 0.0889 - amazon_score: 0.9125 - acc: 0.9657 - val_loss: 0.0941 - val_amazon_score: 0.9030 - val_acc: 0.9637
Epoch 6/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0862 - amazon_score: 0.9152 - acc: 0.9667Epoch 00005: val_loss did not improve
1000/1000 [==============================] - 642s - loss: 0.0862 - amazon_score: 0.9152 - acc: 0.9667 - val_loss: 0.0979 - val_amazon_score: 0.9045 - val_acc: 0.9633
Epoch 7/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0816 - amazon_score: 0.9202 - acc: 0.9684Epoch 00006: val_loss did not improve

Epoch 00006: reducing learning rate to 1.9999999494757503e-05.
1000/1000 [==============================] - 643s - loss: 0.0815 - amazon_score: 0.9203 - acc: 0.9684 - val_loss: 0.0985 - val_amazon_score: 0.9017 - val_acc: 0.9626
Epoch 8/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0763 - amazon_score: 0.9250 - acc: 0.9701Epoch 00007: val_loss did not improve

Epoch 00007: reducing learning rate to 3.999999898951501e-06.
1000/1000 [==============================] - 656s - loss: 0.0763 - amazon_score: 0.9250 - acc: 0.9701 - val_loss: 0.0946 - val_amazon_score: 0.9061 - val_acc: 0.9644
Epoch 9/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0742 - amazon_score: 0.9270 - acc: 0.9713Epoch 00008: val_loss improved from 0.09408 to 0.09406, saving model to weights-v12-f4.hdf5

Epoch 00008: reducing learning rate to 7.999999979801942e-07.
1000/1000 [==============================] - 658s - loss: 0.0742 - amazon_score: 0.9270 - acc: 0.9713 - val_loss: 0.0941 - val_amazon_score: 0.9058 - val_acc: 0.9642
Epoch 10/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0730 - amazon_score: 0.9278 - acc: 0.9718Epoch 00009: val_loss improved from 0.09406 to 0.09307, saving model to weights-v12-f4.hdf5
1000/1000 [==============================] - 658s - loss: 0.0730 - amazon_score: 0.9278 - acc: 0.9718 - val_loss: 0.0931 - val_amazon_score: 0.9084 - val_acc: 0.9649
Epoch 11/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0717 - amazon_score: 0.9293 - acc: 0.9723Epoch 00010: val_loss did not improve
1000/1000 [==============================] - 656s - loss: 0.0716 - amazon_score: 0.9293 - acc: 0.9723 - val_loss: 0.0944 - val_amazon_score: 0.9079 - val_acc: 0.9650
Epoch 12/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0738 - amazon_score: 0.9278 - acc: 0.9713Epoch 00011: val_loss improved from 0.09307 to 0.09294, saving model to weights-v12-f4.hdf5
1000/1000 [==============================] - 658s - loss: 0.0738 - amazon_score: 0.9278 - acc: 0.9713 - val_loss: 0.0929 - val_amazon_score: 0.9076 - val_acc: 0.9644
Epoch 13/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0708 - amazon_score: 0.9305 - acc: 0.9727Epoch 00012: val_loss improved from 0.09294 to 0.09245, saving model to weights-v12-f4.hdf5
1000/1000 [==============================] - 658s - loss: 0.0708 - amazon_score: 0.9305 - acc: 0.9727 - val_loss: 0.0924 - val_amazon_score: 0.9107 - val_acc: 0.9648
Epoch 14/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0711 - amazon_score: 0.9308 - acc: 0.9726Epoch 00013: val_loss did not improve
1000/1000 [==============================] - 656s - loss: 0.0711 - amazon_score: 0.9308 - acc: 0.9726 - val_loss: 0.0945 - val_amazon_score: 0.9076 - val_acc: 0.9647
Epoch 15/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0714 - amazon_score: 0.9302 - acc: 0.9725Epoch 00014: val_loss did not improve

Epoch 00014: reducing learning rate to 5e-07.
1000/1000 [==============================] - 656s - loss: 0.0714 - amazon_score: 0.9302 - acc: 0.9725 - val_loss: 0.0948 - val_amazon_score: 0.9071 - val_acc: 0.9640
Epoch 16/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0719 - amazon_score: 0.9294 - acc: 0.9721Epoch 00015: val_loss did not improve
1000/1000 [==============================] - 656s - loss: 0.0719 - amazon_score: 0.9294 - acc: 0.9721 - val_loss: 0.0938 - val_amazon_score: 0.9090 - val_acc: 0.9647
Epoch 17/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0712 - amazon_score: 0.9295 - acc: 0.9725Epoch 00016: val_loss did not improve
1000/1000 [==============================] - 656s - loss: 0.0712 - amazon_score: 0.9295 - acc: 0.9726 - val_loss: 0.0940 - val_amazon_score: 0.9080 - val_acc: 0.9649
Epoch 18/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0707 - amazon_score: 0.9314 - acc: 0.9726Epoch 00017: val_loss did not improve
1000/1000 [==============================] - 656s - loss: 0.0707 - amazon_score: 0.9314 - acc: 0.9726 - val_loss: 0.0957 - val_amazon_score: 0.9076 - val_acc: 0.9641
Epoch 19/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0704 - amazon_score: 0.9300 - acc: 0.9728Epoch 00018: val_loss did not improve
1000/1000 [==============================] - 656s - loss: 0.0704 - amazon_score: 0.9300 - acc: 0.9728 - val_loss: 0.0947 - val_amazon_score: 0.9099 - val_acc: 0.9643
Epoch 20/30
 999/1000 [============================>.] - ETA: 0s - loss: 0.0709 - amazon_score: 0.9308 - acc: 0.9725Epoch 00019: val_loss did not improve
1000/1000 [==============================] - 656s - loss: 0.0709 - amazon_score: 0.9307 - acc: 0.9725 - val_loss: 0.0949 - val_amazon_score: 0.9068 - val_acc: 0.9645
Epoch 21/30
 467/1000 [=============>................] - ETA: 300s - loss: 0.0709 - amazon_score: 0.9303 - acc: 0.9727