{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common - Package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print function is ready to serve\n"
     ]
    }
   ],
   "source": [
    "# print_function for compatibility with Python 3\n",
    "from __future__ import print_function\n",
    "print('print function is ready to serve')\n",
    "\n",
    "# Matplotlib for visualization\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# display plots in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# NumPy for numerical computing\n",
    "import numpy as np\n",
    "np.random.seed(923)\n",
    "import random\n",
    "random.seed(923)\n",
    "\n",
    "# Pandas for DataFrames\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_column', 100)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import threading\n",
    "from skimage import io\n",
    "from skimage.transform import rescale, resize, downscale_local_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./utils')\n",
    "\n",
    "from data import Data\n",
    "from models import Models, TargetStopping\n",
    "from tags import Tags\n",
    "tags = Tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PLANET_KAGGLE_ROOT = '/data/planet-data/'\n",
    "if not os.path.exists(PLANET_KAGGLE_ROOT):\n",
    "    PLANET_KAGGLE_ROOT = '/Users/jiayou/Documents/Kaggle Data/Amazon'\n",
    "\n",
    "N_TAGS = 17\n",
    "N_TRAIN = 40479\n",
    "N_TEST_T = 40669\n",
    "N_TEST_F = 20522\n",
    "N_TEST = N_TEST_T + N_TEST_F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_on_gpu(val=0, toy=None, d=None, name='', gpu=0):\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "        sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            with tf.device('/gpu:{}'.format(gpu)):\n",
    "                train(val=val, toy=toy, d=d, name=name)\n",
    "    \n",
    "def train(val=0, toy=None, d=None, name=''):\n",
    "    print('')\n",
    "    print('Training {} with val = {}'.format(name, val))\n",
    "    print('')\n",
    "    \n",
    "    if d is None:\n",
    "        d = Data(tif=False, toy=toy)\n",
    "        \n",
    "    gen_val = None\n",
    "    val_steps = None\n",
    "    if val is not None:\n",
    "        gen_val = d.gen_val(100, val=val)\n",
    "        val_steps = 80\n",
    "\n",
    "    m = Models.new_incnet()\n",
    "    \n",
    "    for layer in m.layers:\n",
    "        layer.trainable = False\n",
    "    m.layers[-1].trainable = True\n",
    "    m.compile(metrics=[Models.amazon_score, 'accuracy'],\n",
    "              loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.001))\n",
    "    h = m.fit_generator(\n",
    "        d.gen_train(32, val=val), steps_per_epoch=1300,\n",
    "        epochs=1, initial_epoch=0,\n",
    "        validation_data=gen_val, validation_steps=val_steps,\n",
    "        max_q_size=10)    \n",
    "    \n",
    "    for layer in m.layers:\n",
    "        layer.trainable = True\n",
    "    lrs = [1e-4, 1e-5, 1e-6]\n",
    "    epochs = [6, 3, 3]\n",
    "    loss_stop = np.random.uniform(0.059, 0.065)\n",
    "    initial_epoch = 1\n",
    "    for lr, epoch in zip(lrs, epochs):\n",
    "        m.compile(metrics=[Models.amazon_score, 'accuracy'],\n",
    "                  loss='binary_crossentropy',\n",
    "                  optimizer=Adam(lr=lr))\n",
    "        h = m.fit_generator(\n",
    "            d.gen_train(32, val=val), steps_per_epoch=1300,\n",
    "            epochs=initial_epoch + epoch, initial_epoch=initial_epoch,\n",
    "            validation_data=gen_val, validation_steps=val_steps,\n",
    "            callbacks=[\n",
    "                ModelCheckpoint('weights-{}.hdf5'.format(name), monitor='loss', save_best_only=True, verbose=1),\n",
    "                TargetStopping(monitor='loss', target=loss_stop, verbose=1)\n",
    "            ],\n",
    "            max_q_size=10, verbose=0)\n",
    "        initial_epoch += epoch\n",
    "        \n",
    "    return h\n",
    "\n",
    "def tune_on_gpu(val=0, d=None, name='', gpu=0):\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "        sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            with tf.device('/gpu:{}'.format(gpu)):\n",
    "                tune(val=val, d=d, name=name)\n",
    "\n",
    "def tune(name='', val=0, d=None):\n",
    "    print('')\n",
    "    print('Tuning {} with val = {}'.format(name, val))\n",
    "    print('')\n",
    "    \n",
    "    if d is None:\n",
    "        d = Data(tif=False)\n",
    "        \n",
    "    gen_val = None\n",
    "    val_steps = None\n",
    "    if val is not None:\n",
    "        gen_val = d.gen_val(100, val=val)\n",
    "        val_steps = 80\n",
    "\n",
    "    m = Models.load_incnet('weights-{}.hdf5'.format(name))\n",
    "    m.compile(metrics=['accuracy'],\n",
    "              loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=1e-6))\n",
    "\n",
    "    h = m.fit_generator(\n",
    "        d.gen_train(32, val=val), steps_per_epoch=1300,\n",
    "        epochs=15, initial_epoch=13,\n",
    "        validation_data=gen_val, validation_steps=val_steps,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint('weights-{}-tune.hdf5'.format(name), monitor='loss', save_best_only=True, verbose=1)\n",
    "        ],\n",
    "        max_q_size=10, verbose=0)\n",
    "        \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download pretrained weights to local disk\n",
    "Models.new_incnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parallel ensemble training\n",
    "toy = None\n",
    "d = Data(tif=False, toy=toy)\n",
    "ts = []\n",
    "for i in range(8):\n",
    "    t = threading.Thread(\n",
    "        target=train_on_gpu, \n",
    "        kwargs={'val': None, 'd': d, 'toy': None, 'name': 'v13-n{}'.format(i), 'gpu': i})\n",
    "    t.start()\n",
    "    ts.append(t)\n",
    "for i in range(len(ts)):\n",
    "    ts[i].join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ensemble training\n",
    "toy = 10000\n",
    "results = []\n",
    "d = Data(tif=False, toy=toy)\n",
    "for i in [0]:\n",
    "    r = train(val=i, d=d, toy=toy)\n",
    "    results.append(r)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parallel tuning\n",
    "toy = None\n",
    "d = Data(tif=False, toy=toy)\n",
    "ts = []\n",
    "for i in range(8):\n",
    "    t = threading.Thread(\n",
    "        target=tune_on_gpu, \n",
    "        kwargs={'val': None, 'd': d, 'name': 'v13-n{}'.format(i), 'gpu': i})\n",
    "    t.start()\n",
    "    ts.append(t)\n",
    "for i in range(len(ts)):\n",
    "    ts[i].join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Tag fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mask_weights(w, select):\n",
    "    for i in range(N_TAGS):\n",
    "        if not i in select:\n",
    "            w[318][:,i] = 0\n",
    "            w[319][i] = -1e7\n",
    "    return w\n",
    "\n",
    "def tune_tag(weights, select=[], val=0, toy=None, d=None):\n",
    "    print('')\n",
    "    print('Training with val = {}'.format(val))\n",
    "    print('')\n",
    "    \n",
    "    if d is None:\n",
    "        d = Data(tif=False, toy=toy)\n",
    "\n",
    "    m = Models.load_resnet50(weights)\n",
    "    m.set_weights(mask_weights(m.get_weights(), select))\n",
    "    m.compile(metrics=['accuracy'],\n",
    "              loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001))\n",
    "\n",
    "    h = m.fit_generator(\n",
    "        d.gen_mask(d.gen_train(32, val=val), select=select), steps_per_epoch=1000,\n",
    "        epochs=10, initial_epoch=0,\n",
    "        validation_data=d.gen_mask(d.gen_val(100, val=val), select=select), validation_steps=80,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint('weights-v9-f{}-tune.hdf5'.format(val), save_best_only=True, verbose=1),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=0, min_lr=5e-7, verbose=1)],\n",
    "        max_q_size=10)\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = None\n",
    "pred8 = None\n",
    "\n",
    "def predict_val(toy=None, batch_size=20, weights='', d=None, val=0):\n",
    "    model = Models.load_resnet50(weights)\n",
    "    print('Model weights loaded')\n",
    "    \n",
    "    if d is None:\n",
    "        d = Data(toy=toy)\n",
    "    \n",
    "    cnt = 0\n",
    "    global pred\n",
    "    global pred8\n",
    "    n = len(d.y[val])\n",
    "    pred = np.zeros((n, N_TAGS))\n",
    "    pred8 = np.zeros((n * 8, N_TAGS))\n",
    "    \n",
    "    print('Start predicting..')\n",
    "    for X in d.gen_val_augmented(batch_size, val=val):\n",
    "        y = model.predict_on_batch(X)\n",
    "        k = int(len(y) / 8 + 0.1)\n",
    "        pred8[cnt*8:(cnt+k)*8,:] = y[:,:]\n",
    "        for i in range(k):\n",
    "            pred[cnt+i,:] = d.consolidate(y[8*i:8*(i+1),:])\n",
    "        cnt += k\n",
    "        print('Predicted {} images'.format(cnt))\n",
    "    print('Predicted all {} images'.format(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select = [2, 4, 7, 12]\n",
    "val = 4\n",
    "d = Data(tif=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tune_tag('weights-v9-f{}.hdf5'.format(val), select=select, val=val, d=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_val(d=d, weights='weights-v9-f{}-tune.hdf5'.format(val), val=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags.plot_roc(pred, d.y[val], title='Fine tune tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.597374889411837"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
